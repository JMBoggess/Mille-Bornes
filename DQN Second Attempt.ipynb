{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc6f94d-d51f-4301-ab96-88b8a18bcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import environment as env\n",
    "import policy\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df5de82-4660-41f0-a13b-d6631e34bfb9",
   "metadata": {},
   "source": [
    "# Deep Q Network for Mille Bornes - Second Attempt\n",
    "Goals for this attempt:\n",
    "- Learn how to store a trained model\n",
    "- Implement a replay buffer (instead of training every game, create a replay buffer and sample experiences)\n",
    "- Implement Fixed Q-Value Targets (two models, an online and a target model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c11ef58-3dfd-46d0-b94c-ae5eea325db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters and variables\n",
    "discount_factor = 0.9  # Discount factor of future rewards\n",
    "optimizer = keras.optimizers.Adam(learning_rate=.001)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "model_input_shape = [47]\n",
    "model_n_outputs = 97\n",
    "model_folder = \"Larry\"\n",
    "\n",
    "# Card and Action matrix\n",
    "card_matrix = env.card_matrix_build()\n",
    "action_matrix = env.action_matrix_build(card_matrix)\n",
    "\n",
    "# Replay buffer\n",
    "#  Only experiences for the DQN player are stored\n",
    "#  Inner lists of equal length: states, actions, rewards, next states, dones\n",
    "#    Next states = state for \"dones\" (couldn't think of a good way to account for no next states)\n",
    "#    dones: 0 = no, game continued; 1 = yes, game over\n",
    "replay_buffer = [ [], [], [], [], [] ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bd7dcfd-b4b4-44f7-a359-7d609d9da31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model functions\n",
    "\n",
    "def model_create():\n",
    "    \"\"\"\n",
    "    Create a new Sequential model\n",
    "    \n",
    "    Return - Sequential model object\n",
    "    \"\"\"\n",
    "    return keras.models.Sequential([\n",
    "        keras.layers.Dense(32, activation=\"elu\", input_shape=model_input_shape),\n",
    "        keras.layers.Dense(32, activation=\"elu\"),\n",
    "        keras.layers.Dense(model_n_outputs)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824f55f1-b451-42cd-813e-ebfdee1c044a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds to the replay buffer at the conclusion of a game\n",
    "def replay_buffer_append(game, player_index):\n",
    "    \"\"\"\n",
    "    Player experience collection\n",
    "    \n",
    "    game (environment.Game) - the instance of the Game class that was played\n",
    "    \n",
    "    player_index (int) - the index of the DQN player to store experiences\n",
    "    \"\"\"\n",
    "    # Empty list to populate game experiences\n",
    "    player_experience = [ [], [], [], [], [] ]\n",
    "    \n",
    "    # Used to calculate the player's reward for a full round of play (reward = player action points + team player action points - opponent players action points)\n",
    "    reward_round = 0\n",
    "    \n",
    "    # Player object - simply checking DQN player versus action history log\n",
    "    player = game.players[player_index]\n",
    "    \n",
    "    # Loop in reverse to calculate rewards from a given action\n",
    "    for act in reversed(game.action_history):\n",
    "        if act[0] == player and act[2] > -1:\n",
    "           # Record this action and reset reward round for this player\n",
    "            reward_round += act[3]\n",
    "            player_experience[0].append(act[1])  # State\n",
    "            player_experience[1].append(act[2])  # Action\n",
    "            player_experience[2].append(reward_round)  # Reward\n",
    "            if len(player_experience[0]) > 1:\n",
    "                player_experience[3].append(player_experience[0][-2])  # Next State\n",
    "                player_experience[4].append(0) # Done\n",
    "            else:\n",
    "                player_experience[3].append(act[1]) # Next State\n",
    "                player_experience[4].append(1) # Done\n",
    "\n",
    "            reward_round = 0\n",
    "        else:\n",
    "            # Adjust reward\n",
    "            reward_round += act[3] * (1 if act[0].team == player.team else -1)\n",
    "               \n",
    "    # Reverse list orders to be in game play order and append to buffer\n",
    "    for i in range(5):\n",
    "        player_experience[i].reverse()\n",
    "        replay_buffer[i].extend(player_experience[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bb8cffe-3117-4d45-b8b3-8d2e4de59a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a sample of experiences from the replay buffer\n",
    "def replay_buffer_sample(batch_size):\n",
    "    \"\"\"\n",
    "    Return a sample of experiences from the replay buffer\n",
    "    \n",
    "    batch_size (int) - the number of experiences to sample\n",
    "    \"\"\"\n",
    "    \n",
    "    indices = np.random.randint(len(replay_buffer[0]), size=batch_size)\n",
    "    \n",
    "    # itemgetter = operator class; * - converts the indices to an integer scalar array\n",
    "    states = np.array(itemgetter(*indices)(replay_buffer[0]))\n",
    "    actions = np.array(itemgetter(*indices)(replay_buffer[1]))\n",
    "    rewards = np.array(itemgetter(*indices)(replay_buffer[2]))\n",
    "    next_states = np.array(itemgetter(*indices)(replay_buffer[3]))\n",
    "    dones = np.array(itemgetter(*indices)(replay_buffer[4]))\n",
    "    \n",
    "    return states, actions, rewards, next_states, dones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a688c450-b418-4c51-b036-7d343af0fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model using a sample of experiences from the buffer\n",
    "def train_model(batch_size):\n",
    "    \"\"\"\n",
    "    Train the model\n",
    "    \n",
    "    player_experience - the arrays associated with the desired player\n",
    "    \"\"\"\n",
    "    \n",
    "    # Data for person to process\n",
    "    states, actions, rewards, next_states, dones = replay_buffer_sample(batch_size)\n",
    "\n",
    "    # ----- Q values for next states\n",
    "    Q_values_next_state = model_target.predict(next_states, verbose=0)\n",
    "\n",
    "    # Filter next state Q values to only valid actions\n",
    "    valid_actions = [env.actions_space(next_state, card_matrix, action_matrix) for next_state in next_states]\n",
    "    Q_values_next_state_valid = [\n",
    "        [Q_values_next_state[i][j] for j in valid_actions[i]]\n",
    "        for i in range(len(Q_values_next_state))\n",
    "    ]\n",
    "\n",
    "    # Get the max Q value for each next state\n",
    "    Q_values_next_state_max = [max(q) for q in Q_values_next_state_valid]\n",
    "\n",
    "    # Convert to numpy array\n",
    "    Q_values_next_state_max = np.array(Q_values_next_state_max)\n",
    "    dones = np.array(dones)\n",
    "\n",
    "    # Target Q values: Bellman function: rewards + discounted future rewards (max Q value from the next state as model is assumed to act optimally)\n",
    "    Q_values_target = (rewards + (1 - dones) * discount_factor * Q_values_next_state_max)\n",
    "\n",
    "    # ----- Q values for states, compute loss and train model\n",
    "\n",
    "    # Create mask to retain only the actions that were taken for each action\n",
    "    mask = tf.one_hot(actions, model_n_outputs)\n",
    "\n",
    "    # Calculate the gradient descent (target values the model would have taken under optimal scenario vs. actual actions taken)\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Retrieve Q values for all possible actions in each state\n",
    "        Q_values_state_all = model(states)\n",
    "\n",
    "        # Retain only Q values for actions taken (state-action pair - uses \"mask\")\n",
    "        Q_values_state = tf.reduce_sum(Q_values_state_all * mask, axis=1, keepdims=True)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = tf.reduce_mean(loss_fn(Q_values_target, Q_values_state))\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6cb54b9-10ad-41f8-aaad-53810828d420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a game\n",
    "def play_game(players_name, players_policy, epsilon):\n",
    "    \"\"\"\n",
    "    players_name ([str]) - name of players\n",
    "    players_policy ([str]) - policy to apply to each player\n",
    "    epsilon (dec) - value to use when evaluating the explore/exploit policy\n",
    "    \n",
    "    Return Game\n",
    "    \"\"\"\n",
    "    game = env.Game(players_name)\n",
    "    \n",
    "    # Loop game play\n",
    "    while game.play_status < 4:\n",
    "        # Policy\n",
    "        policy_type = players_policy[players_name.index(game.player_current.name)]\n",
    "        if policy_type == \"dqn\":\n",
    "            action = policy.dqn(model, np.array(game.state()), game.player_actions, epsilon)\n",
    "        elif policy_type == \"program\":\n",
    "            action = policy.program(game.player_actions)\n",
    "        else:\n",
    "            action = policy.rand(game.player_actions)\n",
    "        \n",
    "        # Play the step\n",
    "        game.play_action(action)\n",
    "    \n",
    "    return game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b617c91-dd67-4c81-99d0-0b6dcd9e5ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play a tournament (multiple games)\n",
    "def play_tournament(players_name, players_policy, n_games, train_batch_size):\n",
    "    \"\"\"\n",
    "    Play's multiple games for the specific players based on their policies\n",
    "    \n",
    "    players_name ([str]) - player's names\n",
    "    players_policy ([str]) - policy to decide action for each player\n",
    "    n_games (int) - number of games to play\n",
    "    train_batch_size (int) - number of steps/turns to pull from the buffer to train the model each time\n",
    "    \"\"\"\n",
    "    \n",
    "    # General variables\n",
    "    players_count = len(players_name)\n",
    "    players_range = range(players_count)\n",
    "    teams_count = players_count if players_count < 4 else players_count // 2\n",
    "    teams_range = range(teams_count)\n",
    "    dqn_player_index = players_policy.index('dqn')\n",
    "    dqn_team_index = dqn_player_index if players_count < 4 else dqn_player_index % teams_count  # Team the DQN player is on              \n",
    "    \n",
    "    # Statistics to track\n",
    "    winner_team = []\n",
    "    dqn_rewards = []\n",
    "    \n",
    "    # After 90% of games have been run, epsilon should be 0.01 (highest liklihood the policy will select the DQN option)\n",
    "    epsilon_max = int(n_games * .9)\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        # Determine epsilon for DQN\n",
    "        epsilon = max(1 - i / epsilon_max, 0.01)\n",
    "        \n",
    "        # Play a game and then get player's experiences (replay buffer)\n",
    "        game = play_game(players_name, players_policy, epsilon)\n",
    "        replay_buffer_append(game, dqn_player_index)\n",
    "        \n",
    "        # Track statistics\n",
    "        team_points = game.final_team_points()\n",
    "        max_points = max(team_points)\n",
    "        winner_team.append(team_points.index(max_points) if team_points.count(max_points) == 1 else -1)\n",
    "        dqn_rewards.append(np.sum([team_points[i] * (1 if i == dqn_team_index else -1) for i in teams_range]))\n",
    "        \n",
    "        # Train the model (for Larry) (skip the first few episode/game to ensure the buffer is large enough)\n",
    "        if i > 5:\n",
    "            train_model(train_batch_size)\n",
    "        \n",
    "        # Update the target model after every 50 games\n",
    "        if i % 50 == 0:\n",
    "            model_target.set_weights(model.get_weights())\n",
    "        \n",
    "    # Return statistics\n",
    "    return (winner_team, dqn_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5cd21691-9fb8-45ec-9239-efda5ec14509",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002E04F522710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 999us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 998us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1000us/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: Larry\\assets\n"
     ]
    }
   ],
   "source": [
    "# Core code: First pass\n",
    "\n",
    "# Create a new model\n",
    "model = model_create()\n",
    "\n",
    "# Setup target model\n",
    "model_target = keras.models.clone_model(model)\n",
    "model_target.set_weights(model.get_weights())\n",
    "\n",
    "# Setup parameters\n",
    "players = ['Bob', 'Larry', 'Jr']\n",
    "policies = ['random', 'dqn', 'program']\n",
    "n_games = 500\n",
    "train_batch_size = 50\n",
    "\n",
    "# Play the tournament\n",
    "winner_team, dqn_rewards = play_tournament(players, policies, n_games, train_batch_size)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_folder)\n",
    "\n",
    "# Write team wins to file (note, this code only works for 2 or 3 players)\n",
    "file_wins = open('log_wins.csv', 'a+')\n",
    "for i in range(len(policies)):\n",
    "    file_wins.write(f\"{policies[i]},{int(np.sum([1 for win in winner_team if win == i]))},{n_games}\\n\")\n",
    "\n",
    "file_wins.write(f\"ties,{int(np.sum([1 for win in winner_team if win == -1]))},{n_games}\\n\")\n",
    "\n",
    "file_wins.close()\n",
    "    \n",
    "# Write DQN Rewards to file\n",
    "file_dqn_rewards = open('log_rewards.csv', mode='a+')\n",
    "for reward in dqn_rewards:\n",
    "    file_dqn_rewards.write(f\"{reward}\\n\")\n",
    "file_dqn_rewards.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a385de74-f78c-454a-adfe-6aae30b9718b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: Larry\\assets\n"
     ]
    }
   ],
   "source": [
    "# Resume training\n",
    "\n",
    "# Load saved model\n",
    "model = keras.models.load_model(model_folder)\n",
    "\n",
    "# Setup target model\n",
    "model_target = keras.models.clone_model(model)\n",
    "model_target.set_weights(model.get_weights())\n",
    "\n",
    "# Setup parameters\n",
    "players = ['Bob', 'Larry', 'Jr']\n",
    "policies = ['random', 'dqn', 'program']\n",
    "n_games = 1000\n",
    "train_batch_size = 50\n",
    "\n",
    "# Play the tournament\n",
    "winner_team, dqn_rewards = play_tournament(players, policies, n_games, train_batch_size)\n",
    "\n",
    "# Save the model\n",
    "model.save(model_folder)\n",
    "\n",
    "# Write team wins to file (note, this code only works for 2 or 3 players)\n",
    "file_wins = open('log_wins.csv', 'a+')\n",
    "for i in range(len(policies)):\n",
    "    file_wins.write(f\"{policies[i]},{int(np.sum([1 for win in winner_team if win == i]))},{n_games}\\n\")\n",
    "\n",
    "file_wins.write(f\"ties,{int(np.sum([1 for win in winner_team if win == -1]))},{n_games}\\n\")\n",
    "\n",
    "file_wins.close()\n",
    "    \n",
    "# Write DQN Rewards to file\n",
    "file_dqn_rewards = open('log_rewards.csv', mode='a+')\n",
    "for reward in dqn_rewards:\n",
    "    file_dqn_rewards.write(f\"{reward}\\n\")\n",
    "file_dqn_rewards.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1cc7a108-64bd-4099-8527-c61cc6ab9c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "Bob: 20 wins\n",
      "Larry: 42 wins\n",
      "Jr: 432 wins\n",
      "Ties: 6 wins\n",
      "Total Games: 500\n"
     ]
    }
   ],
   "source": [
    "# Play some games using only the model (exploit not explore)\n",
    "\n",
    "# Load saved model\n",
    "model = keras.models.load_model(model_folder)\n",
    "\n",
    "# Setup parameters\n",
    "players = ['Bob', 'Larry', 'Jr']\n",
    "policies = ['random', 'dqn', 'program']\n",
    "n_games = 500\n",
    "epsilon = 0.0\n",
    "winner_team = []\n",
    "    \n",
    "# Play games\n",
    "for i in range(n_games):\n",
    "    # Play a game\n",
    "    game = play_game(players, policies, epsilon)\n",
    "        \n",
    "    # Track statistics\n",
    "    team_points = game.final_team_points()\n",
    "    max_points = max(team_points)\n",
    "    winner_team.append(team_points.index(max_points) if team_points.count(max_points) == 1 else -1)\n",
    "\n",
    "# Return winner counts\n",
    "for i in range(len(players)):\n",
    "    print(f\"{players[i]}: {int(np.sum([1 for win in winner_team if win == i]))} wins\")\n",
    "\n",
    "print(f\"Ties: {int(np.sum([1 for win in winner_team if win == -1]))} wins\")\n",
    "print(f\"Total Games: {n_games}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62df8c-1ac1-41a4-a232-e32f73f59735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
